{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33ZuUfnAun8W"
   },
   "source": [
    "## Creating a Simple Autoencoder\n",
    "\n",
    "By: V. Ashley Villar (PSU)\n",
    "\n",
    "In this problem set, we will use Pytorch to learn a latent space for the same galaxy image dataset we have previously played with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F9TS8c_-lg55",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: astronn in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: seaborn in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (0.11.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (0.24.2)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (4.62.3)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (21.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (1.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (3.4.2)\n",
      "Requirement already satisfied: astroquery in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (0.4.3)\n",
      "Requirement already satisfied: astropy in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (4.3.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (1.3.2)\n",
      "Requirement already satisfied: h5py in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astronn) (3.2.1)\n",
      "Requirement already satisfied: pyerfa>=1.7.3 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astropy->astronn) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.4.3 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astroquery->astronn) (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.3.2 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astroquery->astronn) (4.10.0)\n",
      "Requirement already satisfied: html5lib>=0.999 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astroquery->astronn) (1.1)\n",
      "Requirement already satisfied: keyring>=4.0 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astroquery->astronn) (23.1.0)\n",
      "Requirement already satisfied: pyvo>=1.1 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astroquery->astronn) (1.1)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from astroquery->astronn) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from beautifulsoup4>=4.3.2->astroquery->astronn) (2.2.1)\n",
      "Requirement already satisfied: webencodings in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from html5lib>=0.999->astroquery->astronn) (0.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from keyring>=4.0->astroquery->astronn) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from importlib-metadata>=3.6->keyring>=4.0->astroquery->astronn) (3.5.0)\n",
      "Requirement already satisfied: mimeparse in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from pyvo>=1.1->astroquery->astronn) (0.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from requests>=2.4.3->astroquery->astronn) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from requests>=2.4.3->astroquery->astronn) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from requests>=2.4.3->astroquery->astronn) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from requests>=2.4.3->astroquery->astronn) (3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from matplotlib->astronn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from matplotlib->astronn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from matplotlib->astronn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from matplotlib->astronn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from matplotlib->astronn) (8.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from pandas->astronn) (2021.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from scikit-learn->astronn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from scikit-learn->astronn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from scikit-learn->astronn) (1.0.1)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "dlopen(/opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/defs.cpython-38-darwin.so, 2): Symbol not found: _H5Pget_fapl_ros3\n  Referenced from: /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/defs.cpython-38-darwin.so\n  Expected in: /opt/miniconda3/envs/DSFP/lib/libhdf5.103.dylib\n in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/defs.cpython-38-darwin.so",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b9/8phngt794pz7f7rdycf1xddm0000gn/T/ipykernel_15676/1389741188.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_galaxy10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgalaxy10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgalaxy10cls_lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/astroNN/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapogee_distances\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_apogee_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapogee_rc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_apogee_rc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgalaxy10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mload_galaxy10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH5Compiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastroNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH5Loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/astroNN/datasets/galaxy10.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdf5_version_tuple\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdf5_built_version_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/version.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_h5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5.pyx\u001b[0m in \u001b[0;36minit h5py.h5\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/defs.cpython-38-darwin.so, 2): Symbol not found: _H5Pget_fapl_ros3\n  Referenced from: /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/defs.cpython-38-darwin.so\n  Expected in: /opt/miniconda3/envs/DSFP/lib/libhdf5.103.dylib\n in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages/h5py/defs.cpython-38-darwin.so"
     ]
    }
   ],
   "source": [
    "!pip install astronn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from astroNN.datasets import load_galaxy10\n",
    "from astroNN.datasets.galaxy10 import galaxy10cls_lookup\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5\n",
      "  Downloading h5-0.5.2-py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: numpy!=1.19.4,>=1.7 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from h5) (1.20.3)\n",
      "Requirement already satisfied: h5py<4.0.0,>=3.2.0 in /opt/miniconda3/envs/DSFP/lib/python3.8/site-packages (from h5) (3.2.1)\n",
      "Installing collected packages: h5\n",
      "Successfully installed h5-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjgT74iXu-KP"
   },
   "source": [
    "# Problem 1a: Understanding our dataset...again\n",
    "\n",
    "Our data is a little too big for us to train an autoencoder in ~1 minute. Let's lower the resolution of our images and only keep one filter. Plot an example of the lower resolution galaxies.\n",
    "\n",
    "Next, flatten each image into a 1D array. Then rescale the flux of the images such that the mean is 0 and the standard deviation is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M3Gg9-a_lp-V"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_galaxy10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b9/8phngt794pz7f7rdycf1xddm0000gn/T/ipykernel_15512/1711457219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Readin the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_galaxy10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_galaxy10' is not defined"
     ]
    }
   ],
   "source": [
    "# Readin the data\n",
    "images, labels = load_galaxy10()\n",
    "labels = labels.astype(np.float32)\n",
    "images = images.astype(np.float32)\n",
    "images = torch.tensor(images)\n",
    "labels = torch.tensor(labels)\n",
    "# Cut down the resolution of the images!!! What is this line doing in words?\n",
    "images = images[:,::6,::6,1]\n",
    "images\n",
    "\n",
    "#Plot an example image here\n",
    "\n",
    "#Flatten images here\n",
    "\n",
    "#Normalize the flux of the images here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6-GabIrvqUc"
   },
   "source": [
    "# Problem 1b. \n",
    "Split the training and test set with a 66/33 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXVYGbcMlzed"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoOK468Nv4dA"
   },
   "source": [
    "# Problem 2: Understanding the Autoencoder\n",
    "\n",
    "Below is sample of an autoencoder, built in Pytorch. Describe the code line-by-line with a partner. Add another hidden layer before and after the encoded (latent) layer (this will be a total of 2 new layers). Choose the appropriate activation function for this regression problem. Make all of the activation functions the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR5y59MfnFF2"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):\n",
    "      # this defines the model\n",
    "        def __init__(self, input_size, hidden_size, hidden_inner, encoded_size):\n",
    "            super(Autoencoder, self).__init__()\n",
    "            print(input_size,hidden_size,encoded_size)\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.encoded_size = encoded_size\n",
    "            self.hidden_inner = hidden_inner\n",
    "            self.hiddenlayer1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            # ADD A LAYER HERE\n",
    "            self.encodedlayer = torch.nn.Linear(self.hidden_inner, self.encoded_size)\n",
    "            self.hiddenlayer3 = torch.nn.Linear(self.encoded_size, self.hidden_inner)\n",
    "            # ADD A LAYER HERE\n",
    "            self.outputlayer = torch.nn.Linear(self.hidden_size, self.input_size)\n",
    "            # some nonlinear options\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            self.softmax = torch.nn.Softmax()\n",
    "            self.relu = torch.nn.ReLU()\n",
    "        def forward(self, x):\n",
    "            layer1 = self.hiddenlayer1(x)\n",
    "            activation1 = self.ACTIVATION?(layer1)\n",
    "            layer2 = self.hiddenlayer2(activation1)\n",
    "            activation2 = self.ACTIVATION?(layer2)\n",
    "            layer3 = self.encodedlayer(activation2)\n",
    "            activation3 = self.ACTIVATION?(layer3)\n",
    "            layer4 = self.hiddenlayer3(activation3)\n",
    "            activation4 = self.ACTIVATION?(layer4)\n",
    "            layer5 = self.hiddenlayer4(activation4)\n",
    "            activation5 = self.ACTIVATION?(layer5)\n",
    "            layer6 = self.outputlayer(activation5)\n",
    "            output = self.ACTIVATION?(layer6)\n",
    "\n",
    "            # Why do I have two outputs?\n",
    "            return output, layer3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSr4XllBX-Nb"
   },
   "source": [
    "# Problem 3. Training\n",
    "\n",
    "This is going to be a lot of guess-and-check. You've been warned. In this block, we will train the autoencoder. Add a plotting function into the training.\n",
    "\n",
    "Note that instead of cross-entropy, we use the \"mean-square-error\" loss. Switch between SGD and Adam optimized. Which seems to work better? Optimize the `learning-rate` parameter and do *not* change other parameters, like momentum.\n",
    "\n",
    "Write a piece of code to run train_model for 10 epochs. Play with the size of each hidden layer and encoded layer. When you feel you've found a reasonable learning rate, up this to 100 (or even 500 if you're patient) epochs. Hint: You want to find MSE~0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qYsd2nlo8Nu"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(training_data,test_data, model):\n",
    "  # define the optimization\n",
    "  criterion = torch.nn.MSELoss()\n",
    "\n",
    "  # Choose between these two optimizers\n",
    "  #optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "  #optimizer = torch.optim.Adam(model.parameters(), lr=0.1,weight_decay=1e-6)\n",
    "\n",
    "  for epoch in range(500):\n",
    "    # clear the gradient\n",
    "    optimizer.zero_grad()\n",
    "    # compute the model output\n",
    "    myoutput, encodings_train = model(training_data)\n",
    "    # calculate loss\n",
    "    loss = criterion(myoutput, training_data)\n",
    "    # credit assignment\n",
    "    loss.backward()\n",
    "    # update model weights\n",
    "    optimizer.step()\n",
    "    # Add a plot of the loss vs epoch for the test and training sets here\n",
    "\n",
    "#Do your training here!!\n",
    "hidden_size_1 = 100\n",
    "hidden_size_2 = 50\n",
    "encoded_size = 10 \n",
    "model = Autoencoder(np.shape(images_train[0])[0],hidden_size_1,hidden_size_2,encoded_size)\n",
    "train_model(images_train, images_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zWYWVOuYvP4"
   },
   "source": [
    "# Problem 4a. Understand our Results\n",
    "\n",
    "Plot an image (remember you will need to reshape it to a 14x14 grid) with imshow, and plot the autoencoder output for the same galaxy. Try plotting the difference between the two. What does your algorithm do well reconstructing? Are there certain features which it fails to reproduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08bqiTkdB1Xx"
   },
   "outputs": [],
   "source": [
    "#Make an image of the original image\n",
    "\n",
    "#Make an image of its reconstruction\n",
    "\n",
    "#Make an image of (original - reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5YQIsfC7C9n"
   },
   "source": [
    "# Problem 4b. \n",
    "\n",
    "Make a scatter plot of two of the 10 latent space dimensions. Do you notice any interesting correlations between different subsets of the latent space? Any interesting clustering?\n",
    "\n",
    "Try color coding each point by the galaxy label using `plt.scatter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZcz3_OwBvAx"
   },
   "outputs": [],
   "source": [
    "#Scatter plot between two dimensions of the latent space\n",
    "#Try coloring the points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL5yNDE37TCE"
   },
   "source": [
    "# Bonus Problem 5a Playing with the Latent Space\n",
    "\n",
    "Create a random forest classifier to classiy each galaxy using only your latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtBA7LDkznuO"
   },
   "outputs": [],
   "source": [
    "\n",
    "clf = RandomForestClassifier(...)\n",
    "\n",
    "clf.fit(...)\n",
    "new_labels = clf.predict(...)\n",
    "\n",
    "cm = confusion_matrix(labels_test,new_labels,normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xeo_dn8j7fNd"
   },
   "source": [
    "# Bonus Problem 5b Playing with the Latent Space\n",
    "\n",
    "Create an isolation forest to find the most anomalous galaxies. Made a cumulative distribution plot showing the anomaly scores of each class of galaxies. Which ones are the most anomalous? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjWqRJjgOTKf"
   },
   "outputs": [],
   "source": [
    "clf = IsolationForest(...).fit(encodings)\n",
    "scores = -clf.score_samples(encodings) #I am taking the negative because the lowest score is actually the weirdest, which I don't like...\n",
    "\n",
    "#Plot an image of the weirdest galazy!\n",
    "\n",
    "#This plots the cumulative distribution\n",
    "def cdf(x, label='',plot=True, *args, **kwargs):\n",
    "    x, y = sorted(x), np.arange(len(x)) / len(x)\n",
    "    return plt.plot(x, y, *args, **kwargs, label=label) if plot else (x, y)\n",
    "\n",
    "ulabels = np.unique(labels)\n",
    "for ulabel in ulabels:\n",
    "  gind = np.where(labels==ulabel)\n",
    "  cdf(...)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoencodersBlank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
